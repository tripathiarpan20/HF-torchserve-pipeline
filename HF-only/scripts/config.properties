'''
References:
https://github.com/pytorch/serve/blob/master/docs/configuration.md


'''

inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
number_of_netty_threads=32
job_queue_size=1000

'''
#The path of folder in which model archives (.mar files) are present
#This can be overrided by `--model-store` option in the `torchserve --start --ts-config config.properties` command
#Reference: https://github.com/pytorch/serve/blob/master/docs/configuration.md#command-line-parameters 

However, since the objective in this repo is to deploy Docker containers, we leave the name as 

'''
model_store=model-store

#Indicates that all models present in the `model_store` folder would be loaded during `torchserve --start` command
load_models=all
default_workers_per_model=4

#This line is important for installing custom requirements in Torchserve Docker container with `requirements.txt` file

#https://pytorch.org/serve/configuration.html#allow-model-specific-custom-python-packages
#https://github.com/pytorch/serve/tree/master/model-archiver#torch-model-archiver-command-line-interface

install_py_dep_per_model=true
